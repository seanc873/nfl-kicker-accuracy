---
title: "m"
output: html_document
date: "2025-03-25"
---

```{r}
# Load necessary libraries
library(dplyr)

# Step 1: Load and Merge Data

process_kick_data <- function(years, output_file) {
  library(dplyr)
  
  all_data <- list()
  
  for (year in years) {
    # Load the kick data
    kick_data <- read.csv(paste0("processed_data/wt_with_plays_filtered", year, ".csv"))
    
    # Load the angle data
    angle_data <- read.csv(paste0("analysis_data/updated_predictions_complete_", year, ".csv"))
    
    # Load the weather data
    weather_data <- read.csv(paste0("analysis_data/playerweather_coords_", year, ".csv"))
    
    # Create FG_success and XP_success indicators
    kick_data <- kick_data %>%
      filter(specialTeamsResult %in% c("Kick Attempt Good", "Kick Attempt No Good")) %>%
      mutate(FG_success = ifelse(specialTeamsPlayType == "Field Goal" & specialTeamsResult == "Kick Attempt Good", 1,
                                 ifelse(specialTeamsPlayType == "Field Goal" & specialTeamsResult == "Kick Attempt No Good", 0, NA)),
             XP_success = ifelse(specialTeamsPlayType == "Extra Point" & specialTeamsResult == "Kick Attempt Good", 1,
                                 ifelse(specialTeamsPlayType == "Extra Point" & specialTeamsResult == "Kick Attempt No Good", 0, NA)))
    
    # Remove duplicate rows based on playId, frameId, and gameId, keeping only one row per group
    kick_data <- kick_data %>%
      group_by(gameId, playId, frameId) %>%
      slice(1) %>%
      ungroup()
    
    # Merge the kick data with angle data
    merged_data <- kick_data %>%
      left_join(angle_data %>% select(gameId, playId, real_angle, deviation_distance), by = c("gameId", "playId"))
    
    # Merge the resulting data with weather data
    merged_data <- merged_data %>%
      left_join(weather_data %>% select(gameId, playId, WindSpeed, Temperature, Humidity), by = c("gameId", "playId"))
    
    # Remove duplicate rows and filter event types
    merged_data <- merged_data %>%
      group_by(gameId, playId, frameId) %>%
      slice(1) %>%
      ungroup() %>%
      filter(event != "None") %>%
      filter(event %in% c("field_goal", "field_goal_missed", "extra_point", "extra_point_missed"))
    
    # Clean up column names
    merged_data <- merged_data %>%
      select(-frameId, -WindSpeed.y, -Temperature.y, -Humidity.y, -event) %>%
      rename(WindSpeed = WindSpeed.x, 
             Temperature = Temperature.x, 
             Humidity = Humidity.x)
    
    # Add year column
    merged_data$year <- year
    
    # Store in list
    all_data[[as.character(year)]] <- merged_data
  }
  
  # Combine all years into one dataframe
  final_data <- bind_rows(all_data)
  
  # Write to CSV
  write.csv(final_data, output_file, row.names = FALSE)
}

# Run the function for years 2018, 2019, 2020
years <- c(2018, 2019, 2020)
output_file <- "modelling_data/merged_for_logistic.csv"
process_kick_data(years, output_file)
```





```{r}
# Load necessary libraries
library(dplyr)

# Load the data
modelling_data <- read.csv("modelling_data/merged_for_logistic.csv")

# Clean the data: Filter out rows with NA in the success columns and relevant predictors
modelling_data <- modelling_data %>%
  filter(!is.na(real_angle), !is.na(deviation_distance), !is.na(Temperature), !is.na(Humidity), !is.na(WindSpeed), !is.na(kickLength))

# Logistic Regression for Field Goals
# Only keep rows where FG_success is defined
fg_data <- modelling_data %>%
  filter(!is.na(FG_success))

fg_model <- glm(FG_success ~ real_angle + deviation_distance + Temperature + Humidity + WindSpeed + kickLength,
                family = binomial(link = "logit"),
                data = fg_data)

# Summary of the Field Goal model
summary(fg_model)

# Predict probabilities for Field Goals
fg_data$fg_predicted_probabilities <- predict(fg_model, newdata = fg_data, type = "response")

# Logistic Regression for Extra Points
# Only keep rows where XP_success is defined
xp_data <- modelling_data %>%
  filter(!is.na(XP_success))

xp_model <- glm(XP_success ~ real_angle + deviation_distance + Temperature + Humidity + WindSpeed + kickLength,
                family = binomial(link = "logit"),
                data = xp_data)

# Summary of the Extra Point model
summary(xp_model)

# Predict probabilities for Extra Points
xp_data$xp_predicted_probabilities <- predict(xp_model, newdata = xp_data, type = "response")

# Combine predictions back into the original modelling_data
modelling_data <- modelling_data %>%
  left_join(fg_data %>% select(gameId, playId, fg_predicted_probabilities), by = c("gameId", "playId")) %>%
  left_join(xp_data %>% select(gameId, playId, xp_predicted_probabilities), by = c("gameId", "playId"))

modelling_data$fg_predicted_probabilities <- round(modelling_data$fg_predicted_probabilities, 6)
modelling_data$xp_predicted_probabilities <- round(modelling_data$xp_predicted_probabilities, 6)

# View the final data with predicted probabilities
head(modelling_data %>% select(gameId, playId, FG_success, XP_success, kickLength, fg_predicted_probabilities, xp_predicted_probabilities))
```

```{r}
# Load necessary libraries
library(dplyr)

file1 <- read.csv("analysis_data/updated_predictions_complete_2018.csv")
file2 <- read.csv("analysis_data/updated_predictions_complete_2019.csv")
file3 <- read.csv("analysis_data/updated_predictions_complete_2020.csv")
combined_data <- rbind(file1, file2, file3)

# Merge the predicted probabilities into the new dataset
merged_data <- combined_data %>%
  left_join(modelling_data %>% select(gameId, playId, fg_predicted_probabilities, xp_predicted_probabilities), 
            by = c("gameId", "playId")) %>% mutate(season = as.integer(substr(as.character(gameId), 1, 4))) %>% 
  mutate(
    starting_x = ifelse(predicted_x == 120, 120 - starting_x, starting_x), predicted_x = ifelse(predicted_x == 120, 0, predicted_x)) %>%
  select(season, everything()) %>% select(-playDirection, -ideal_angle)

# Load the main dataset
pred_data <- merged_data

# Load season-specific kick data
kick_data_2018 <- read.csv("processed_data/wt_with_plays_filtered2018.csv") %>%
  select(gameId, playId, kickLength)

kick_data_2019 <- read.csv("processed_data/wt_with_plays_filtered2019.csv") %>%
  select(gameId, playId, kickLength)

kick_data_2020 <- read.csv("processed_data/wt_with_plays_filtered2020.csv") %>%
  select(gameId, playId, kickLength)

# Merge kickLength based on season
pred_data <- pred_data %>%
  mutate(season = as.integer(substr(as.character(gameId), 1, 4))) %>%
  left_join(bind_rows(
    mutate(kick_data_2018, season = 2018),
    mutate(kick_data_2019, season = 2019),
    mutate(kick_data_2020, season = 2020)
  ), by = c("gameId", "playId", "season")) %>% distinct()

# Save updated file
write.csv(pred_data, "modelling_data/pred_with_prob_kickLength.csv", row.names = FALSE)
```

```{r}
library(dplyr)
library(readr)

# Load datasets
df_logistic <- read_csv("modelling_data/merged_for_logistic.csv")
df_pred <- read_csv("modelling_data/pred_with_prob_kickLength.csv")

# Determine play type in df_pred based on NA values in probability columns
df_pred <- df_pred %>%
  mutate(
    is_fg = !is.na(fg_predicted_probabilities),  # FG kicks have fg_probabilities
    is_xp = !is.na(xp_predicted_probabilities)  # XP kicks have xp_probabilities
  )

# Filter FG and XP kicks separately
df_fg_logistic <- df_logistic %>% filter(specialTeamsPlayType == "Field Goal")
df_xp_logistic <- df_logistic %>% filter(specialTeamsPlayType == "Extra Point")

df_fg_pred <- df_pred %>% filter(is_fg)
df_xp_pred <- df_pred %>% filter(is_xp)

# Compute raw FG% and XP% from actual makes
compute_raw_percent <- function(df, success_col) {
  df %>%
    group_by(displayName) %>%
    summarise(
      attempts = n(),
      makes = sum(!!sym(success_col), na.rm = TRUE),
      raw_percent = makes / attempts
    )
}

raw_fg <- compute_raw_percent(df_fg_logistic, "FG_success") %>% rename(raw_fg_percent = raw_percent)
raw_xp <- compute_raw_percent(df_xp_logistic, "XP_success") %>% rename(raw_xp_percent = raw_percent)

# Compute RB-FG% and RB-XP% using Beta-Bernoulli model
compute_rb_percent <- function(df, prob_col, alpha0 = 1, beta0 = 1) {
  df %>%
    group_by(displayName) %>%
    summarise(
      attempts = n(),
      sum_p = sum(!!sym(prob_col), na.rm = TRUE),  # Sum of predicted probabilities
      alpha = sum_p + alpha0,  
      beta = (attempts - sum_p) + beta0,  
      rb_percent = alpha / (alpha + beta)  # Posterior mean for RB-FG% or RB-XP%
    ) %>%
    select(displayName, rb_percent)
}

rb_fg <- compute_rb_percent(df_fg_pred, "fg_predicted_probabilities") %>% rename(rb_fg_percent = rb_percent)
rb_xp <- compute_rb_percent(df_xp_pred, "xp_predicted_probabilities") %>% rename(rb_xp_percent = rb_percent)

# Merge all metrics into a single table
kicker_stats <- full_join(raw_fg, rb_fg, by = "displayName") %>%
  full_join(raw_xp, by = "displayName") %>%
  full_join(rb_xp, by = "displayName") %>%
  rename(fg_attempts = attempts.x, fg_makes = makes.x, xp_attempts = attempts.y, xp_makes = makes.y)

write_csv(kicker_stats, "modelling_data/rb_kicker_stats.csv")

# View results
print(kicker_stats)
```


```{r}
library(tidyverse)

# Load data
df <- read_csv("modelling_data/rb_kicker_stats.csv")  

# Convert to long format for ggplot
df_long <- df %>%
  pivot_longer(cols = c(raw_fg_percent, rb_fg_percent, raw_xp_percent, rb_xp_percent),
               names_to = "metric",
               values_to = "percentage")

# Compute standard deviations per metric
std_dev_summary <- df_long %>%
  group_by(metric) %>%
  summarise(std_dev = sd(percentage, na.rm = TRUE))

print(std_dev_summary)  # Check computed standard deviations

# Plot boxplots
ggplot(df_long, aes(x = metric, y = percentage, fill = metric)) +
  geom_boxplot() +
  labs(title = "Standard Deviations for FG and XP (Raw vs RB)",
       x = "Metric",
       y = "Percentage") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

